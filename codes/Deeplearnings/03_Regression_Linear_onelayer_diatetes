{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"authorship_tag":"ABX9TyNCChy0WQCUGXGiGfw/Xkfu","include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/HueyVault/study_NLPs/blob/main/codes/DeepLearnings/03_Regresstion_Linear_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"## 데이터 수집\n","metadata":{"id":"UDB893xWJypr"}},{"cell_type":"code","source":"from sklearn.datasets import load_diabetes\ndata_diabetes = load_diabetes()\nfeatures, label = data_diabetes.data, data_diabetes.target","metadata":{"id":"0QGhgqc2I36u"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"features.shape, label.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDblcighJ_8U","outputId":"0e4e2235-b384-475c-d00c-2a5e3570d988"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((442, 10), (442,))"]},"metadata":{},"execution_count":5}],"execution_count":5},{"cell_type":"markdown","source":"\n## 데이터 전처리\n- 데이터 분석","metadata":{"id":"lUIiFIcKKIQr"}},{"cell_type":"markdown","source":"## 데이터 분할\n- train, test, validation","metadata":{"id":"ZFwb3gUXKenT"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_features, test_features, train_label, test_label = train_test_split(features, label, test_size=0.2, random_state=42)","metadata":{"id":"nLb_4UkSKe6C"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_features.shape, test_features.shape, train_label.shape, test_label.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89GU1BE0LD0b","outputId":"96b36377-ba0b-4611-a87b-ec19f21b75da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((353, 10), (89, 10), (353,), (89,))"]},"metadata":{},"execution_count":7}],"execution_count":7},{"cell_type":"code","source":"type(train_features), type(test_features), type(train_label), type(test_label)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMsLb4NCLO8T","outputId":"59176918-54ad-46ba-940d-a1be9b85ea0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"]},"metadata":{},"execution_count":8}],"execution_count":8},{"cell_type":"code","source":"import torch","metadata":{"id":"AB77Um8oLaTi"},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_features_tensor = torch.tensor(train_features, dtype=torch.float32)\ntrain_label_tensor = torch.tensor(train_label, dtype=torch.float32).view(-1,1) # 행만 있는 경우 행열로 변환 해줌\n# test_features_tensor = torch.tensor(test_features)\n# test_label_tensor = torch.tensor(test_label)\ntype(train_features_tensor), type(train_label_tensor)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dQppqhSLeyT","outputId":"ed386869-3b63-4dad-f4aa-41f851047d72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Tensor, torch.Tensor)"]},"metadata":{},"execution_count":22}],"execution_count":22},{"cell_type":"code","source":"train_features_tensor.shape, train_label_tensor.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAKGOWdPL8y0","outputId":"85012a38-4e13-44c3-b161-028cc0d70ba0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([353, 10]), torch.Size([353, 1]))"]},"metadata":{},"execution_count":23}],"execution_count":23},{"cell_type":"markdown","source":"## 모델 학습\n\n","metadata":{"id":"6f789iE6Klfr"}},{"cell_type":"code","source":"# simple model linear regression\n# model, loss function, optimizer function\nclass LinearRegression(torch.nn.Module) :\n    def __init__(self, input_dim, output_dim): # input : feature 의 열 갯수, output : label의 카테고리 갯수 (연속형은 값 하나)\n        super(LinearRegression, self).__init__()\n        self.linear = torch.nn.Linear(input_dim,output_dim)\n\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n","metadata":{"id":"tKYtxnRpMI4k"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_features_tensor.shape[1], train_label_tensor.shape[1]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Lw855O9OUTk","outputId":"ff2dd1c5-dcdc-40b5-ef75-1dd082bd07e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 1)"]},"metadata":{},"execution_count":15}],"execution_count":15},{"cell_type":"code","source":"model = LinearRegression(train_features_tensor.shape[1], train_label_tensor.shape[1])","metadata":{"id":"umcPAfVsOLXE"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1haY7fgPN9b","outputId":"4f733b04-3201-400d-bbd6-2bf4362c6a6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(\n","  (linear): Linear(in_features=10, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":18}],"execution_count":18},{"cell_type":"code","source":"criterion = torch.nn.MSELoss() # Loss function\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Optimizer fuction, lr = learnning rate : gradient decsent 빠르게 찾기 최근에 ADAMW 가 제일 좋다. 찾아가는 과정 어렵다. 그래서 optimizer 성능 중요하다.","metadata":{"id":"J83domFsVd1-"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"## 반복 학습\n# for epoch in range(10):\nfor epoch in range(1000):\n    pred_y = model.forward(train_features_tensor)\n    loss = criterion(pred_y, train_label_tensor)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"epoch : {epoch}, loss : {loss.item()}\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRH4rddcWqSm","outputId":"fab01dff-ab99-4e25-bd3a-4bbaffd8d469"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch : 0, loss : 16616.94921875\n","epoch : 100, loss : 6164.419921875\n","epoch : 200, loss : 5906.201171875\n","epoch : 300, loss : 5829.5791015625\n","epoch : 400, loss : 5758.3837890625\n","epoch : 500, loss : 5689.4404296875\n","epoch : 600, loss : 5622.62060546875\n","epoch : 700, loss : 5557.85107421875\n","epoch : 800, loss : 5495.0634765625\n","epoch : 900, loss : 5434.189453125\n"]}],"execution_count":26},{"cell_type":"markdown","source":"## 모델 평가\n\n","metadata":{"id":"1nvzhmSzKmhL"}},{"cell_type":"code","source":"model.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxtyxKJPYpP-","outputId":"5d883e40-7797-446a-e7b6-9b1f94eb5893"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(\n","  (linear): Linear(in_features=10, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":27}],"execution_count":27},{"cell_type":"code","source":"with torch.no_grad(): # 학습 목정이 아닌 평가 목적 위해 고정\n    pred_y = model(train_features_tensor)\n    loss = criterion(pred_y, train_label_tensor) # 예측도 간은 loss function\n    print(f\"loss : {loss.item()}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aIcWupFYt-X","outputId":"0f6a0057-e281-4a94-80d8-19cea59ee422"},"outputs":[{"output_type":"stream","name":"stdout","text":["loss : 5375.16552734375\n"]}],"execution_count":28},{"cell_type":"markdown","source":"## 모델 배포","metadata":{"id":"SMKe4XqnKoYC"}}]}